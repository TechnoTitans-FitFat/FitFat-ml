{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask_cors\n",
        "\n",
        "from flask_cors import CORS\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "meal_types = [\"soup\", \"dessert\", \"meat\", \"salad\", \"sandwich\", \"drink\"]\n",
        "meal_classes = [\"breakfast\", \"lunch\", \"dinner\"]\n",
        "\n",
        "def classify_meal(user_input):\n",
        "    meal_result = classifier(user_input, meal_types)\n",
        "    meal_type = meal_result[\"labels\"][0]\n",
        "\n",
        "    meal_class = \"none\"\n",
        "    for time in meal_classes:\n",
        "        if time in user_input.lower():\n",
        "            meal_class = time\n",
        "            break\n",
        "\n",
        "    return meal_class, meal_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG8VV6bvuQBx",
        "outputId": "0889a132-c58d-4b22-b190-5feb70ed9b53",
        "collapsed": true
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting flask_cors\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: flask_cors\n",
            "Successfully installed flask_cors-5.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input = input()\n",
        "# meal_class , meal_type = classify_meal(user_input)"
      ],
      "metadata": {
        "id": "WrNvkNLOuwbB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# id = \"67e2c086d79fa311a7e9e65b\"\n",
        "def fetch_data(user_id):\n",
        "      health_URL = f\"https://fitfat-backend.up.railway.app/api/healthInfo/{user_id}\"\n",
        "      diet_URL = f\"https://fitfat-backend.up.railway.app/api/dietInfo/{user_id}\"\n",
        "      response1 = requests.get(health_URL)\n",
        "      response1.raise_for_status()\n",
        "      data1 = response1.json()\n",
        "      response2 = requests.get(diet_URL)\n",
        "      response2.raise_for_status()\n",
        "      data2 = response2.json()\n",
        "      return data1[\"healthInfo\"] , data2[\"dietInfo\"]\n",
        "\n",
        "# health_data, diet_data = fetch_data()\n",
        "# merged_data = {\n",
        "#             \"userId\": id,\n",
        "#             \"allergy\": health_data.get(\"foodAllergies\").lower(),\n",
        "#             \"diabetes\": int(health_data.get(\"diabetes\", False)),\n",
        "#             \"diet\": diet_data.get(\"dietType\").lower(),\n",
        "#             \"protein\": diet_data.get(\"macronutrientGoals\", {}).get(\"proteins\"),\n",
        "#             \"carb\": diet_data.get(\"macronutrientGoals\", {}).get(\"carbs\"),\n",
        "#             \"fat\": diet_data.get(\"macronutrientGoals\", {}).get(\"fats\"),\n",
        "#             \"calories\": diet_data.get(\"macronutrientGoals\", {}).get(\"calories\"),\n",
        "#             \"type\": meal_type,\n",
        "#             \"class\": meal_class\n",
        "#         }\n",
        "\n",
        "# user_df = pd.DataFrame([merged_data])\n",
        "# display(user_df)"
      ],
      "metadata": {
        "id": "IW0pJ8PQvFA7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "import pymongo\n",
        "from bson.objectid import ObjectId\n",
        "MONGO_URI = \"mongodb+srv://fitfat1:fitfat@fitfat.tdzwb.mongodb.net/\"\n",
        "\n",
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "\n",
        "db = client[\"test\"]\n",
        "collection = db[\"recipes\"]\n",
        "data = list(collection.find())\n",
        "df = pd.DataFrame(data)\n",
        "df.drop(columns=['image'], inplace=True)\n",
        "df.drop(df.loc[df['_id'] == ObjectId(\"67ded27af1a796cc42250b4e\")].index, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lp-U20fFvURW",
        "outputId": "91545e27-7b9e-4dc3-a27f-1b394b08f530"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = [\"ingredients\", \"diabetes\", \"category\", \"allergy\", \"diet\", \"type\"]\n",
        "for i in col:\n",
        "    df[i] = df[i].apply(lambda x: x[0] if isinstance(x, list) and len(x) == 1  else x)\n",
        "nutrient = [\"fat\", \"protein\", \"carb\", \"fiber\"]\n",
        "for i in nutrient:\n",
        "    df[i] = df[i].str.replace(\"g\", \"\").astype(float).astype(int)\n",
        "for column in [\"class\", \"type\"]:\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].apply(lambda x: [item.lower() for item in x] if isinstance(x, list) else (x.lower() if isinstance(x, str) else x))\n",
        "df[\"category\"] = df[\"category\"].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "2sjSATG3vq_8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colum = [\"_id\", \"diet\", \"diabetes\", \"allergy\", \"protein\", \"calories\", \"carb\", \"fat\", \"type\", \"class\"]\n",
        "meal_data = df[colum]\n",
        "# display(meal_data)"
      ],
      "metadata": {
        "id": "UyjmR5Q9vxY3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meal_data = meal_data.copy()\n",
        "meal_data[\"diabetes\"] = meal_data[\"diabetes\"].astype(int)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Xj9HCQXGv6dE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder , StandardScaler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(meal_data['class'])\n",
        "\n",
        "encoders = {}\n",
        "cat_col = [\"diet\", \"allergy\", \"type\"]\n",
        "for col in cat_col:\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(meal_data[col])\n",
        "    encoders[col] = encoder\n",
        "def encoding(data):\n",
        "    if type(data[\"class\"][0]) == list:\n",
        "      encoded_data = pd.DataFrame(mlb.transform(data['class']), columns=mlb.classes_)\n",
        "      data_new = data.drop(columns=['class'])\n",
        "      data_new = pd.concat([data_new, encoded_data], axis=1)\n",
        "    else:\n",
        "      encoded_data = pd.DataFrame(0, index=data.index, columns=mlb.classes_)\n",
        "      for i, val in enumerate(data[\"class\"]):\n",
        "          if val in mlb.classes_:\n",
        "              encoded_data.loc[i, val] = 1\n",
        "      data_new = data.drop(columns=['class'])\n",
        "      data_new = pd.concat([data_new, encoded_data], axis=1)\n",
        "    for col in cat_col:\n",
        "      cat = f\"{col}_encoded\"\n",
        "      data_new[cat] = data_new[col].apply(lambda x: encoders[col].transform([x])[0] if x in encoders[col].classes_ else 0)\n",
        "      data_new = data_new.drop(columns=[col])\n",
        "    return data_new\n",
        "\n",
        "data_new = encoding(meal_data)"
      ],
      "metadata": {
        "id": "usmj85nZwYSx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['protein', 'calories', 'carb', 'fat']\n",
        "def scale_numerical_features(meals_df, numerical_features):\n",
        "  scaler = StandardScaler()\n",
        "  meals_df[numerical_features] = scaler.fit_transform(meals_df[numerical_features])\n",
        "  return meals_df , scaler\n",
        "data_new, scaler = scale_numerical_features(data_new, numerical_features)\n",
        "# display(data_new)"
      ],
      "metadata": {
        "id": "War2yqlSwoRF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical_features = ['protein', 'calories', 'carb', 'fat']\n",
        "# user_new = encoding(user_df)\n",
        "# user_new[numerical_features] = scaler.transform(user_new[numerical_features])\n",
        "# display(user_new)"
      ],
      "metadata": {
        "id": "5CeGMIjGwt4A"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# col = ['diet_encoded', 'allergy_encoded', 'diabetes', 'type_encoded', 'breakfast',\t'dinner',\t'lunch']\n",
        "# column = []\n",
        "# for i in col:\n",
        "#   if user_new[i].iloc[0]  != 0:\n",
        "#     column.append(i)"
      ],
      "metadata": {
        "id": "8SSDME38xdvp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_temp = train_test_split(data_new[['diet_encoded', 'allergy_encoded', 'diabetes', 'type_encoded', 'breakfast',\t'dinner',\t'lunch']], test_size=0.2, random_state=42)\n",
        "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=16):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "input_dim = X_train.shape[1] #عدد الكولمز\n",
        "model = Autoencoder(input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 90\n",
        "patience = 10\n",
        "best_val_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, X_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, X_val)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f'التوقف المبكر عند Epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, X_test)\n",
        "print(f'Loss on test set: {test_loss.item():.4f}')\n",
        "\n",
        "# X_all = torch.tensor(data_new[col].values, dtype=torch.float32)\n",
        "# with torch.no_grad():\n",
        "#     meal_embeddings = model.encoder(X_all).numpy()\n",
        "#     user_embedding = model.encoder(torch.tensor(user_new[col].values, dtype=torch.float32)).numpy()\n",
        "\n",
        "# similarities = cosine_similarity(user_embedding, meal_embeddings)[0]\n",
        "# best_meal_index = np.argmax(similarities)\n",
        "# best_meal = meal_data.iloc[best_meal_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUuJnBJZTJ8A",
        "outputId": "78fe849d-2499-48c9-f739-129eb1541586"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/90], Loss: 0.9239, Val Loss: 0.8038\n",
            "Epoch [20/90], Loss: 0.4951, Val Loss: 0.5628\n",
            "Epoch [30/90], Loss: 0.3687, Val Loss: 0.3986\n",
            "Epoch [40/90], Loss: 0.1779, Val Loss: 0.1728\n",
            "Epoch [50/90], Loss: 0.1331, Val Loss: 0.1275\n",
            "Epoch [60/90], Loss: 0.0911, Val Loss: 0.0893\n",
            "Epoch [70/90], Loss: 0.0657, Val Loss: 0.0698\n",
            "Epoch [80/90], Loss: 0.0517, Val Loss: 0.0534\n",
            "Epoch [90/90], Loss: 0.0363, Val Loss: 0.0394\n",
            "Loss on test set: 0.0367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display(best_meal)\n",
        "# id = best_meal[\"_id\"]\n",
        "# filtered_rows = df.loc[df[\"_id\"] == id]\n",
        "# display(filtered_rows)"
      ],
      "metadata": {
        "id": "25H0AaxX19iX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route(\"/recommend\", methods=[\"POST\"])\n",
        "\n",
        "def recommend_meal():\n",
        "  data = request.get_json()\n",
        "  user_input = data.get(\"query\", \"\")\n",
        "  user_id = data.get(\"userId\")\n",
        "  meal_class , meal_type = classify_meal(user_input)\n",
        "  health_data, diet_data = fetch_data(user_id)\n",
        "  merged_data = {\n",
        "              \"userId\": user_id,\n",
        "              \"allergy\": health_data.get(\"foodAllergies\", \"\").lower(),\n",
        "              \"diabetes\": int(health_data.get(\"diabetes\", False)),\n",
        "              \"diet\": diet_data.get(\"dietType\", \"\").lower(),\n",
        "              \"protein\": diet_data.get(\"macronutrientGoals\", {}).get(\"proteins\"),\n",
        "              \"carb\": diet_data.get(\"macronutrientGoals\", {}).get(\"carbs\"),\n",
        "              \"fat\": diet_data.get(\"macronutrientGoals\", {}).get(\"fats\"),\n",
        "              \"calories\": diet_data.get(\"macronutrientGoals\", {}).get(\"calories\"),\n",
        "              \"type\": meal_type,\n",
        "              \"class\": meal_class\n",
        "          }\n",
        "\n",
        "  user_df = pd.DataFrame([merged_data])\n",
        "  # display(user_df)\n",
        "  numerical_features = ['protein', 'calories', 'carb', 'fat']\n",
        "  user_new = encoding(user_df)\n",
        "  user_new[numerical_features] = scaler.transform(user_new[numerical_features])\n",
        "  col = ['diet_encoded', 'allergy_encoded', 'diabetes', 'type_encoded', 'breakfast',\t'dinner',\t'lunch']\n",
        "  column = []\n",
        "  for i in col:\n",
        "    if user_new[i].iloc[0]  != 0:\n",
        "      column.append(i)\n",
        "\n",
        "  X_all = torch.tensor(data_new[col].values, dtype=torch.float32)\n",
        "  with torch.no_grad():\n",
        "      meal_embeddings = model.encoder(X_all).numpy()\n",
        "      user_embedding = model.encoder(torch.tensor(user_new[col].values, dtype=torch.float32)).numpy()\n",
        "\n",
        "  similarities = cosine_similarity(user_embedding, meal_embeddings)[0]\n",
        "  best_meal_index = np.argmax(similarities)\n",
        "  best_meal = meal_data.iloc[best_meal_index]\n",
        "\n",
        "  return jsonify({\"recommended_meal\": best_meal.to_dict()})\n",
        "\n",
        "# id = best_meal[\"_id\"]\n",
        "# filtered_rows = df.loc[df[\"_id\"] == id]\n",
        "# display(filtered_rows)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFPZvO-RW45Z",
        "outputId": "383540b3-4bbd-4fbe-a91f-ce067efe2ce6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install onnx\n",
        "\n",
        "# import onnx\n",
        "# model.eval()\n",
        "\n",
        "# dummy_input = torch.randn(1, 7)\n",
        "# torch.onnx.export(model, dummy_input, \"model.onnx\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IMfWr8DKTmFf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install onnx-tf tensorflow\n",
        "\n",
        "# import onnx\n",
        "# from onnx_tf.backend import prepare\n",
        "\n",
        "\n",
        "# onnx_model = onnx.load(\"model.onnx\")\n",
        "# tf_rep = prepare(onnx_model)\n",
        "# tf_rep.export_graph(\"model.pb\")\n",
        "\n",
        "\n",
        "# from tensorflow import keras\n",
        "# from tensorflow import lite\n",
        "# converter=tf.lite.TFLiteConverter.from_keras_model(model.pb)\n",
        "# tfmodel=converter.convert()\n",
        "# open(\"model.tflite\",\"wb\").write(tfmodel)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jPq2wwcDT_sj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# def filter_meals_by_criteria(meals_df, user_data):\n",
        "#     filtered_df = meals_df.copy()\n",
        "#     filtered_df = filtered_df[filtered_df['type_encoded'] == user_data['type_encoded']]\n",
        "#     meal_columns = ['breakfast', 'dinner', 'lunch']\n",
        "#     selected_meals = [col for col in meal_columns if user_data[col] == 1]\n",
        "#     if selected_meals:\n",
        "#         filtered_df = filtered_df[filtered_df[selected_meals].sum(axis=1) > 0]\n",
        "#         print(len(filtered_df))\n",
        "#     else:\n",
        "#         print(\"لا توجد وجبات متطابقة للمستخدم.\")\n",
        "#         filtered_df = meals_df\n",
        "#     return filtered_df\n",
        "\n",
        "# def find_best_meal(user_data, meals_df):\n",
        "#     filtered_meals_df = filter_meals_by_criteria(meals_df, user_data)\n",
        "#     if filtered_meals_df.empty:\n",
        "#         print(\"لا توجد وجبات متطابقة للمستخدم.\")\n",
        "#         filtered_meals_df = meals_df\n",
        "#     # display(filtered_meals_df)\n",
        "#     features = ['diet_encoded', 'allergy_encoded', 'diabetes']\n",
        "#     weights = {'diet_encoded': 1, 'allergy_encoded': 5, 'diabetes': 2}\n",
        "#     weighted_meals = filtered_meals_df[features].copy()\n",
        "#     for feature in features:\n",
        "#         weighted_meals[feature] *= weights[feature]\n",
        "#     # display(weighted_meals)\n",
        "#     user_data_df = pd.DataFrame([user_data])\n",
        "#     weighted_user_features = user_data_df[features].copy()\n",
        "#     for feature in features:\n",
        "#         weighted_user_features[feature] *= weights[feature]\n",
        "#     # display(weighted_user_features)\n",
        "#     similarities = cosine_similarity(weighted_user_features, weighted_meals)[0]\n",
        "#     similarity_scores = similarities\n",
        "\n",
        "#     # nutritional_columns = ['protein', 'calories', 'carb', 'fat']\n",
        "#     # nutritional_deviation = np.abs(filtered_meals_df[nutritional_columns].values - user_data[nutritional_columns].values).mean(axis=1)\n",
        "\n",
        "#     # combined_scores = (\n",
        "#     #     0.8 * similarity_scores -\n",
        "#     #     0.2 * nutritional_deviation\n",
        "#     # )\n",
        "\n",
        "#     best_meal_index = np.argmax(similarity_scores)\n",
        "#     best_meal = filtered_meals_df.iloc[best_meal_index]\n",
        "\n",
        "#     return best_meal\n",
        "# best_meal = find_best_meal(user_new.iloc[0], data_new)\n",
        "# # display(best_meal)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FSHLDV2T18fN"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}